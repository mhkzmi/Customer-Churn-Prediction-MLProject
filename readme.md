# Predicting Customer Churn in Telecom Industry
## A Modular Machine Learning Pipeline with Classical Models


## Overview
This project focuses on predicting customer churn in a telecom company using customer demographic, service usage,
and contract-related data.  
The main objective is to design a **clean, modular, and reproducible machine learning pipeline** and to compare
classical machine learning models under class imbalance conditions.

---

## Dataset
The project uses the **Telco Customer Churn** dataset, which contains customer-level information such as:
- Demographics
- Subscription services
- Contract type and billing details

The target variable is **Churn**, indicating whether a customer left the service.

---

## Data Setup
Download the Telco Customer Churn dataset from Kaggle and place it in:
data/raw/Telco-Customer-Churn.csv

---

## Project Structure
The project follows a modular design:

├── src/  
│   ├── preprocessing/    
│   ├── models/           
│   ├── training/         
│   ├── evaluation/       
│   ├── run_pipeline.py   

This structure ensures separation of concerns and improves reproducibility and maintainability.

---

## Exploratory Data Analysis (EDA)
EDA was performed to understand the data distribution and key drivers of churn, including:
- Churn distribution and class imbalance analysis
- Numerical feature distributions (tenure, MonthlyCharges, TotalCharges)
- Categorical feature analysis (Contract, InternetService, PaymentMethod)
- Correlation analysis between numerical features

More than six meaningful visualizations were created to support these analyses.

---

## Models
The following models were implemented and compared:

- **Logistic Regression** (baseline and final model)
- **Random Forest**
- **Random Forest (class-balanced)**
- **Gradient Boosting Classifier**

Logistic Regression was selected as the final model due to its stable performance,
interpretability, and robustness under class imbalance.

---

## Evaluation
Due to the imbalanced nature of the dataset, **F1-score** was chosen as the primary evaluation metric.
Additional evaluation included:
- Confusion Matrix
- ROC Curve and ROC-AUC

All evaluation metrics and plots are stored in the `results/` directory and are generated by running:

```bash
python src/run_pipeline.py
```

The final Logistic Regression model achieved an F1-score of approximately 0.60 on the test set.

---

## Results

The results/ directory contains:

- JSON files with evaluation metrics for each model
- Confusion matrix and ROC curve plots

These results allow direct comparison between models without re-running the pipeline.

---

## Limitations

- Hyperparameter tuning was not exhaustively performed
- Feature selection was not explicitly applied
- Advanced ensemble models were explored only at a baseline level

The listed limitations also define clear directions for future improvements
and provide a natural extension of the current pipeline.

---

## Future Work

- Hyperparameter tuning (GridSearch / RandomizedSearch)
- Advanced gradient boosting models (XGBoost, LightGBM)
- Feature selection and interaction engineering
- Threshold optimization for improved recall on churned customers